"""
Date:        4/11/2025 
Class:       Database_Handler
Description: This class will be incharge of maintaining and accessing the local db file. The database
             will be SQLite, allowing for flexible and quick storage. The schema is contained in 
             database/schema.sql
"""
from structs import Scan_Result, Signature_Record

import os
import json
import csv
import requests
from tqdm import tqdm
import zipfile
import sqlite3
import logging
logger = logging.getLogger(__name__)

class Database_Handler():
    def __init__(self):
        self.sql_scripts_dir_path = os.path.join(os.path.dirname(__file__), 'database')
        self.db_file_path = os.path.join(self.sql_scripts_dir_path, 'local_db.sqlite')
        self.conn = sqlite3.connect(self.db_file_path)

        self.bazzar_csv_link = 'https://bazaar.abuse.ch/export/csv/full/'

    def __get_script(self, script_name:str):
        with open(os.path.join(self.sql_scripts_dir_path, script_name)) as f:
            return f.read()

    # Executes Schema SQL file
    def initialze_database(self):
        logger.info(" Initializing Database")
        try:
            schema_sql = self.__get_script('schema.sql')

            self.conn.executescript(schema_sql)
            self.conn.commit()
        except Exception as e:
            logger.error(f" Issue Initializing DB{e}: ")

    # Inserts Scan Results Data Class into scan_history table
    def insert_scan_results(self, scan_result:Scan_Result):
        try:
            script = self.__get_script('scan_history_insert.sql')

            cursor = self.conn.cursor()
            cursor.execute(script,(
                scan_result.contains_malicious_files,
                scan_result.scan_path,
                json.dumps(scan_result.files_scanned),
                json.dumps(scan_result.malicous_files),
                scan_result.timestamp
            ))
            
            self.conn.commit()
            cursor.close()
        except Exception as e:
            logger.error(f" An Issue Occured Inserting Into DB: {e}")
            print(e)

    # Private function meant to download the Malware Bazzar CSV for to be loaded into signatures table
    def __download_bazzar_csv(self):
        logger.info(" Downloading Bazar CSV")
        download_path = os.path.join(self.sql_scripts_dir_path, 'bazzar_csv.zip')
    
        response = requests.get(self.bazzar_csv_link, stream=True)
        response.raise_for_status()

        # Start download bar
        total_size = int(response.headers.get('content-length', 0))

        with open(download_path, 'wb') as f, tqdm (
            total=total_size,
            unit='B',
            unit_scale=True,
            unit_divisor=1024,
            desc='Downloading Bazzar CSV'
        ) as progress:
            for chunk in response.iter_content(chunk_size=1024):
                if chunk:
                    f.write(chunk)
                    progress.update(len(chunk))

    # Unzips the file before insertion
    def __unzip_bazzar_csv(self):
        with zipfile.ZipFile(os.path.join(self.sql_scripts_dir_path, 'bazzar_csv.zip'), 'r') as zip_ref:
            zip_ref.extractall(os.path.join(self.sql_scripts_dir_path, 'bazzar'))
            logger.info(' Successfully Extracted Bazar CSV ZIP')

    # Private function designed to load the file downloaed from __download_bazzar_csv__ in signatures table
    def __insert_bazzar_csv__(self, chunk_size=10000):
        def clean_row(row):
            if row[0].startswith('#'):
                return None  
            return Signature_Record(row[1], row[8])
        
        cursor = self.conn.cursor()
        
        # Read in SQL Script
        script = self.__get_script('signatures_record_insert.sql')

        # Read in CSV file in for batch processing
        with open(os.path.join(self.sql_scripts_dir_path, 'bazzar/full.csv'), newline='', encoding='utf-8') as csvfile:
            reader = csv.reader(csvfile)
            total_lines = sum(1 for _ in open(os.path.join(self.sql_scripts_dir_path, 'bazzar/full.csv'), 'r', encoding='utf-8'))
            csvfile.seek(0)  # Reset after counting

            batch = []
            for row in tqdm(reader, total=total_lines, desc="Inserting Bazaar records"):
                cleaned = clean_row(row)                
                if not cleaned:
                    continue
                batch.append([cleaned.sha256, cleaned.file_signature])

                if len(batch) >= chunk_size:
                    cursor.executemany(script, batch)
                    self.conn.commit()
                    batch = []

            if batch:
                cursor.executemany(script, batch)
                self.conn.commit()

            
            cursor.close()

    # Deletes all temporary files created durring the refresh process
    def __cleanup_bazzar_files(self):
        zip = os.path.join(self.sql_scripts_dir_path, 'bazzar_csv.zip')
        csv = os.path.join(self.sql_scripts_dir_path, 'bazzar/full.csv')
        csv_dir = os.path.join(self.sql_scripts_dir_path, 'bazzar/')

        os.remove(zip)
        os.remove(csv)
        os.rmdir(csv_dir)

    # Download, cleans, and loads data into SQLite database
    def refresh_signatures(self):
        self.__download_bazzar_csv()
        self.__unzip_bazzar_csv()
        self.__insert_bazzar_csv__()
        self.__cleanup_bazzar_files()