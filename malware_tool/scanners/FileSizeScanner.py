import os
from typing import List
from structs import File_Scan_Report
from scanners.scanner import Scanner
from tqdm import tqdm
import numpy as np
from scipy.optimize import curve_fit
from concurrent.futures import ThreadPoolExecutor, as_completed
import logging
logger = logging.getLogger(__name__)

class FileSizeScanner(Scanner):
    def __init__(self, db_handler):
        super().__init__(db_handler)
        self.IGNORED_EXTENSIONS = {
            ".log", ".out", ".tmp", ".bak", ".swp", ".swo",
            ".cache", ".pyc", ".class", ".zip", ".tar", ".gz", ".7z",
            ".rar", ".iso", ".img", ".dmg", ".apk", ".xpi",
            ".mp4", ".mp3", ".avi", ".mov", ".flac", ".pdf",
            ".jpg", ".jpeg", ".png", ".bmp", ".gif", ".webp",
            ".db", ".sqlite", ".vmdk", ".vdi", ".qcow2"
        }

    def __analyze__(self, file_history: List[File_Scan_Report]):
        if len(file_history) < 3:
            return {
                "path": file_history[0].path if file_history else None,
                "status": "not enough data",
                "suspicious": False
            }

        # Sort by scan_time (ISO 8601 is lexically sortable)
        sorted_reports = sorted(file_history, key=lambda r: r.scan_time)
        sizes = [r.size_bytes for r in sorted_reports]
        x = np.arange(len(sizes))
        y = np.array(sizes)

        result = {
            "path": sorted_reports[0].path,
            "scan_times": [r.scan_time for r in sorted_reports],
            "sizes": sizes,
            "trend": None,
            "details": {},
            "suspicious": False
        }

        # Fit linear model
        linear_fit = np.polyfit(x, y, 1)
        linear_pred = np.polyval(linear_fit, x)
        linear_error = np.mean(np.abs(y - linear_pred))

        # Fit exponential model
        def exponential(x, a, b):
            return a * np.exp(b * x)

        try:
            exp_params, _ = curve_fit(
                exponential, x, y,
                maxfev=10000,
                bounds=([0, -1], [np.inf, 1])  # a > 0, b in [-1, 1]
            )
            exp_pred = exponential(x, *exp_params)
            exp_error = np.mean(np.abs(y - exp_pred))
        except RuntimeError:
            exp_params = None
            exp_error = float('inf')

        # Decide trend
        if linear_error < exp_error:
            result["trend"] = "linear"
            result["details"]["slope"] = linear_fit[0]
        else:
            result["trend"] = "exponential"
            result["details"]["exp_params"] = exp_params.tolist() if exp_params is not None else None


        result["details"]["linear_error"] = linear_error
        result["details"]["exp_error"] = exp_error

        # Optional: detect abnormal last jump using Z-score
        mean = np.mean(y)
        std = np.std(y)
        if std > 0:
            z_scores = [(val - mean) / std for val in y]
            result["details"]["max_z_score"] = max(abs(z) for z in z_scores)
            if abs(z_scores[-1]) > 2.0:
                result["suspicious"] = True
        else:
            result["details"]["max_z_score"] = 0.0

        return result


    def process_file_path(self, path):

        logger.info(f"Analyzing File Path History {path}")

        past_reports = self.db_handler.search_file_scan_reports(path)

        result = self.__analyze__(past_reports)


        return result["suspicious"]
        


    def scan(self, file_scan_reports: List[File_Scan_Report]):
        file_size_reports = []
        seen_paths = set()
        tasks = []

        with ThreadPoolExecutor(max_workers=8) as executor:
            futures = {}
            for report in file_scan_reports:
                path = report.path
                if path in seen_paths or os.path.splitext(path)[1].lower() in self.IGNORED_EXTENSIONS:
                    continue
                seen_paths.add(path)
                futures[executor.submit(self.process_file_path, path)] = report

            for future in tqdm(as_completed(futures), total=len(futures), desc="File Size Trend Analysis", unit="file"):
                report = futures[future]
                try:
                    is_suspicious = future.result()
                    if is_suspicious:
                        file_size_reports.append(File_Scan_Report(
                            path=report.path,
                            size_bytes=report.size_bytes,
                            is_malware=True,
                            scan_type='file_size_analysis'
                        ))
                except Exception as e:
                    print(f"Error processing {report.path}: {e}")

        return file_size_reports
